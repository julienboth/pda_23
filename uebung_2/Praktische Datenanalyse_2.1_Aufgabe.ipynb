{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Pandas Übung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installieren und Importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kernkomponenten von Pandas: Series und DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die beiden Hauptkomponenten von Pandas sind **Series** und **DataFrame**. \n",
    "\n",
    "Eine `Serie` ist im Wesentlichen eine Spalte und ein `DataFrame` ist eine mehrdimensionale Tabelle, die aus einer Sammlung von Serien besteht.\n",
    "\n",
    "<img src=\"src/series-and-dataframe.png\" width=600px />\n",
    "\n",
    "**DataFrames** und **Series** sind sich insofern sehr ähnlich, als das viele Operationen, die mit dem einen Objekt durchführbar sind, auch mit dem anderen möglich ist (z. B. das Einfügen von Nullwerten und die Berechnung des Mittelwerts).\n",
    "\n",
    "Sie werden sehen, wie diese Komponenten funktionieren, wenn wir unten mit den Daten arbeiten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Datenstruktur Pandas Series ist ein **one-dimensional labelled array**\n",
    "- Ist primärer Baustein für einen DataFrame, aus dem seine Zeilen und Spalten bestehen\n",
    "\n",
    "Die Elemente einer Serie wird wie folgt bestimmt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pandas.Series\n",
    "series = pd.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `data` akzeptiert verschiedene Datentypen wie ndarray, dictionaries und scalar values\n",
    "- `index` Parameter akzeptiert array-like objects, welche erlauben die Index-Axis zu labeln (Wenn kein index-Parameter übergeben wird, dann verwendet Pandas die dictionary keys als Indexbezeichnungen\n",
    "- `dtype` bestimmt den Datentyp für die Series. Wenn kein Datentyp angegeben wird, zieht Pandas den Datentypen, die die Serie haben sollte\n",
    "- `name` Parameter erlaubt die Benamung der Serie, die erstellt wurde\n",
    "\n",
    "Die offizielle Dokumentation zu `Series` findet Ihr hier: [Series Dokumentation Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anwendungsbeispiele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung einer Series mit Hilfe eines Python Dictionaries\n",
    "if __name__ == \"__main__\":\n",
    "    # Erstellung eines Python Dictionaries\n",
    "    data = {\"a\": 1.0, \"b\": 2.0, \"c\": 3.0, \"d\": 4.0}\n",
    "    # Erstellung Series auf Basis Data Dictionaries mit Namen 'series_from_dict'\n",
    "    series = pd.Series(data=data, name=\"series_from_dict\")\n",
    "    print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Erstellung eines NumPy arrays\n",
    "    data = np.random.randint(0, 10, 5)\n",
    "    series = pd.Series(\n",
    "        data=data,\n",
    "        index=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "        name=\"series_from_ndarray\",\n",
    "        dtype=\"int\",\n",
    "    )\n",
    "    print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 1**: Verändere die Variable so, dass die Datenreihe den Datentype float besitzt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Datenstruktur Pandas DataFrame ist eine **two-dimensional data structure**\n",
    "- Besteht aus Zeilen und Spalten\n",
    "- Ähnlich einer relationalen Datenbanktabelle oder einem CSV, sehr ähnlich zu einer Exceltabelle\n",
    "\n",
    "Die Elemente einer DataFrame wird wie folgt bestimmt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pandas.DataFrame\n",
    "df = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Parameter sind sehr ähnlich zu dem einer Serie. Zusätzlich kann über den Parameter `columns` die Spaltennanmen definiert werden.\n",
    "\n",
    "Die offizielle Dokumentation zu `DataFrames` findet Ihr hier: [DataFrame Dokumentation Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anwendungsbeispiele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = {\n",
    "        \"column_a\": pd.Series(\n",
    "            data=np.random.randint(10, 100, 5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "        ),\n",
    "        \"column_b\": pd.Series(\n",
    "            data=np.random.randint(10, 100, 5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "        ),\n",
    "        \"column_c\": pd.Series(\n",
    "            data=np.random.randint(10, 100, 5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "        ),\n",
    "    }\n",
    "    df = pd.DataFrame(data=data)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = {\"column_a\": [1, 2, 3], \"column_b\": [4, 5, 6], \"column_c\": [7, 8, 9]}\n",
    "    df = pd.DataFrame(data=data, index=[\"row_a\", \"row_b\", \"row_c\"])\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Umgang mit DataFrames\n",
    "\n",
    "### 3.1. Laden und Speichern von DataFrames\n",
    "\n",
    "Angenommen wir haben einen Obststand, der Äpfel und Orangen verkauft. Wir möchten eine Spalte für jede Frucht und eine Zeile für jeden Kundenkauf haben. Um dies als Dictionary für Pandas zu organisieren, könnten wir etwas tun wie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"apples\": [3, 2, 0, 1], \"oranges\": [0, 3, 7, 2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 2:** Überführung in ein pandas DataFrame. Nenne den DataFrame `purchases_df` und verwende `index_p` als Index. Jede Obstart hat hierbei eine eigene Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_p = [\"June\", \"Robert\", \"Lily\", \"David\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir eine Bestellung auf Basis des Kundennamens **auffinden** - `loc`ate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_df.loc[\"June\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Einlesen von Datenset auf Basis eines CSVs mit Hilfe von [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVs haben keine Indizes wie unsere DataFrames, also müssen wir beim Lesen die `index_col` definieren\n",
    "df = pd.read_csv(\"./src/purchases.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einlesen der Daten von  JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn Sie eine JSON-Datei haben - die im Wesentlichen ein gespeichertes Python-Dict ist\n",
    "# - kann Pandas diese ebenso einfach lesen:\n",
    "df = pd.read_json(\"./src/purchases.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euch wird aufgefallen sein, dass unser Index dieses Mal korrekt mitkam, da die Verwendung von **JSON die Verschachtelung von Indizes ermöglicht**. \n",
    "\n",
    "Pandas wird versuchen herauszufinden, wie man einen DataFrame erstellt, indem es die Struktur Ihres JSON analysiert, und manchmal wird es nicht direkt funktionieren. Oft muss der Parameter `orient` abhängig von der Struktur gesetzt werden.\n",
    "\n",
    "**Dokumentation:** [.read_json](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rückführung des DataFrames zu CSV oder JSON\n",
    "\n",
    "Nach einer Analyse und Transformation der Daten wird der Bedarf entstehen, die Daten wieder in eine CSV bzw. JSON-Datei zu überführen. Das kann mit einfachen Befehlen geschehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./src/new_purchases.csv\")\n",
    "df.to_json(\"./src/new_purchases.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wichtigste DataFrame Funktionen\n",
    "\n",
    "DataFrames verfügen über Hunderte von Methoden und andere Operationen, die für die jeweilige Analyse nützich sein kann. Als erstes sollten wir die Operationen kennen, die einfache Transformationen der Daten und grundlegende statistische Analysen ermöglichen.\n",
    "\n",
    "Lassen Sie uns zunächst den IMDB-Film-Datensatz laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladet einmal das DataSet und definiert die Index-Zeile mit der Spalte \"Titel\"\n",
    "movies_df = pd.read_csv(\"./src/IMDB-Movie-Data.csv\", index_col=\"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns auch jederzeit den Source Code der Funktion angucken - lass uns einmal einen Blick darauf werfen: [Source Code](https://github.com/pandas-dev/pandas/blob/v1.2.5/pandas/io/parsers.py#L533-L610)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Erstsichtung der Daten\n",
    "\n",
    "Das erste, was man beim Öffnen eines neuen Datensatzes macht, ist, ein paar Zeilen zu visualisieren. Wir erreichen dies mit `.head()`:\n",
    "\n",
    "Dokumentation: [pandas.DataFrame.head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Was sind Eure Beobachtungen hinsichtlich des Datensets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `.head()` werden standardmäßig die **ersten** fünf Zeilen des DataFrames ausgegeben. Wir haben eine Zahl übergeben, `movies_df.head(10)`, sodass die obersten zehn Zeilen ausgeben werden. \n",
    "\n",
    "Um die **letzten** fünf Zeilen zu sehen, kann `.tail()` verwendet werden. Auch `tail()` akzeptiert eine Zahl, und in diesem Fall bilden wir die unteren zehn Zeilen ab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erhalte Informationen über dein Datenset\n",
    "\n",
    "`info()` sollte einer der ersten Befehle sein, die Sie nach dem Laden Ihrer Daten ausführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.info()` bereitgestellte Informationen:\n",
    "- Anzahl der Zeilen und Spalten\n",
    "- Anzahl der **non-null Werte** (siehe fehlende Werte in `Revenue` und `Metascore`)\n",
    "- Größe des DataFrames in Memory\n",
    "- Datentyp pro Zeile (Identifizierung möglicher Umwandlung von String `object` zu `int64` um mathematische Operationen durchzuführen)\n",
    "\n",
    "Eine weitere Information über das Datenset kann über `.shape` eingeholt werden, welches eine Übersicht über die Anzahl der **(Zeilen, Spalten)** gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Möglichkeit die Anzahl der einendeutigen Merkmale ausgeben zu lassen, ist die Funktion `.nunique`. Die Dokumentation hierfür kann **[hier](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html)** entnommen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fragen:**\n",
    "- Wann kann Shape hilfreich sein?\n",
    "- Welches Datenformat ist der Response von `.shape`?\n",
    "\n",
    "**Dokumentation:** https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Umgang mit Duplikaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Datensatz hat keine doppelten Zeilen, aber es ist immer wichtig zu überprüfen, dass keine doppelten Zeilen vorhanden sind. Es kann auch gute Gründe geben, dass doppelte Zeilen vorhanden sind.\n",
    "\n",
    "Um das zu demonstrieren, verdoppeln wir einfach unseren Movie DataFrame, indem wir ihn an sich selbst anhängen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = movies_df.append(movies_df)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verwendung von `append()` gibt eine Kopie zurück, ohne den ursprünglichen DataFrame zu beeinflussen. Wir fangen diese Kopie in `temp` ein, so dass wir nicht mit den echten Daten arbeiten.\n",
    "\n",
    "Beachtet, dass der Aufruf von `.shape` beweist, dass sich unsere DataFrame-Zeilen verdoppelt haben.\n",
    "Jetzt haben wir einen DataFrame, für welchen wir Duplikate löschen `.drop_duplicates()`können. Dafür gibt es folgende Optionen unter dem Parameter `keep`:\n",
    "* `first`: (Voreinstellung) Duplikate bis auf das erste Vorkommen verwerfen\n",
    "* `last`: Duplikate bis auf das letzte Vorkommen verwerfen\n",
    "* `False`: Alle Duplikate verwerfen\n",
    "\n",
    "Dokumentation zu [.drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    "\n",
    "**Frage**: Warum kann der Parameter wichtig sein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutzung von Drop Duplicates\n",
    "temp_df = temp_df.drop_duplicates()\n",
    "\n",
    "# Überprüfung der Ergebnisse\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimierung:** Es ist etwas umständlich, DataFrames immer wieder der gleichen Variablen zuzuweisen, wie in diesem Beispiel. Aus diesem Grund hat das Team um Pandas den Parameter `inplace` bei vielen seiner Methoden eingeführt. Wenn `inplace=True` verwendet wird, wird der DataFrame an Ort und Stelle modifiziert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = movies_df.append(movies_df)\n",
    "temp_df.drop_duplicates(inplace=True, keep=False)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich bei allen Zeilen um Duplikate handelte, wurden mit `keep=False` alle Zeilen gelöscht, so dass null Zeilen übrig blieben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Transformation von Zeilen\n",
    "\n",
    "Oft haben Datensätze wortreiche Spaltennamen mit Symbolen, Wörtern in Groß- und Kleinschreibung, Leerzeichen und Tippfehlern. Um die Auswahl von Daten nach Spaltennamen zu erleichtern, können wir die Spalten in einem Datenset anpassen.\n",
    "\n",
    "Eine erste Übersicht erhalten wir mit `.columns` - dies kann auch hilfreich sein, wenn Ihr einen `Error` erhaltet bei der Selektion einer Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können die Methode `.rename()` und `.columns` verwenden, um bestimmte oder alle Spalten in einem `Dict` umzubenennen. \n",
    "\n",
    "**Aufgabe 3:** \n",
    "- Im ersten Schritt wollen wir die Klammern auflösen, also benennt `Runtime (Minutes)` in `Runtime` und `Revenue (Millions)` in `Revenue_millions` um. Dokumentation könnt Ihr [Dokumentation hier](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) einsehen\n",
    "- Außerdem wollen wir alle Spalten zu `lowercase` umbenennen. Hierzu könnt Ihr die Methode [`.columns`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html#) oder `.rename()` verwenden\n",
    "\n",
    "**Tipp:** Für die 2. Übung, schaut auf List Comprehension für Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist eine gute Idee Kleinbuchstaben zu verwenden, Sonderzeichen zu entfernen und Leerzeichen durch Unterstriche zu ersetzen. Das ist gerade sinnvoll, wenn Ihr eine Zeit lang mit einem Datensatz arbeiten werdet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Umgang mit fehlenden Werten (NULL-Values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir Daten untersuchen, werden wir höchstwahrscheinlich auf fehlende oder Null-Werte stoßen, die im Wesentlichen Platzhalter für nicht vorhandene Werte sind. Am häufigsten werden Sie Pythons `None` oder NumPys `np.nan` sehen, die beide in einigen Situationen unterschiedlich behandelt werden.\n",
    "\n",
    "Wir lernen später mehr, was die Möglichkeiten sind mit fehlenden Werten umzugehen und was dies für Implikationen auf die Datenanalyse hat.\n",
    "\n",
    "Lass uns zuerst einmal die **Gesamtzahl der NULL-Values** in jeder Spalte unseres Datensatzes feststellen. Der erste Schritt besteht darin zu prüfen, welche Zellen in unserem DataFrame null sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'isnull()' gibt ein DataFrame wieder, mit False True Werten, wenn Daten fehlen\n",
    "movies_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dokumentation:** [`.isnull()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html)\n",
    "\n",
    "Um die Anzahl der Nullen in jeder Spalte zu zählen, verwenden wir eine Aggregatfunktion zum Summieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun sehen, dass unsere Daten **128** fehlende Werte für `revenue_millions` und **64** fehlende Werte für `metascore` haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datenanalysten stehen regelmäßig vor dem Dilemma, **Nullwerte zu entfernen oder zu imputieren**, und es ist eine Entscheidung, die eine genaue Kenntnis Eurer Daten und deren Kontext erfordert. Insgesamt wird das Entfernen von Nulldaten nur dann empfohlen, wenn Ihr eine **geringe Menge an fehlenden Daten** haben.\n",
    "\n",
    "Das Entfernen von Zeilen mit **Nullwerten** ist ziemlich einfach mit der Funktion [`.dopna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir Ihr germerkt habt, werden **alle Zeilen gelöscht, die mindestens ein NULL-Value aufweisen**. Die Methode gibt einen neuen DataFrame als Return-Statement zurück. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 4**: \n",
    "- Welchen Parameter müssten wir setzen, um den DataFrame direkt anzupassen?\n",
    "- Welchen Parameter müssten wir anpassen, wenn wir nicht Zeilen sondern Spalten löschen wollen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`BEGRÜNDUNG HERE`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grundsätzlich:** Das Entfernen von 162 Zeilen scheint eine Verschwendung zu sein, weil die Informationen in all den anderen Spalten grundsätzlich okay ist. Es geht eher darum, wie wir die Daten \"imputieren\" können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputieren von Werten\n",
    "\n",
    "Imputation ist eine herkömmliche Technik von Feature Engineering, um Daten mit Nullwerten zu erhalten. \n",
    "\n",
    "Es kann Fälle geben, in denen das Löschen jeder Zeile mit einem Nullwert einen zu großen Teil Ihres Datensatzes entfernt, so dass wir stattdessen diesen Nullwert mit einem anderen Wert imputieren können, normalerweise mit...\n",
    "... dem **Mittelwert** oder\n",
    "... dem **Median** dieser Spalte. \n",
    "\n",
    "Schauen wir uns nun die fehlenden Werte in der Spalte `revenue_millions` an. Zuerst extrahieren wir diese Spalte in eine eigene Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = movies_df[\"revenue_millions\"]\n",
    "print(revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verwendung von eckigen Klammern ist die allgemeine Art, wie wir Spalten in einem DataFrame auswählen. Das geschieht sehr ähnlich zum Kontext und Umgang mit Python Dictionaries. Der Spaltenname ist hier der Key, ähnlich wie bei der Kreierung des DataFrames.\n",
    "\n",
    "**Frage:** Was ist der Pandas Datentyp von der Variable `revenue`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 5:**\n",
    "- Berechne den Mittelwert des `revenue` und befülle die Werte direkt in den DataFrame\n",
    "- Nutze hierfür `fillna` als Funktion im Package Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine ganze Spalte mit demselben Wert zu imputieren, ist ein einfaches Beispiel. Es wäre eine bessere Idee, eine granularere Imputation nach Genre oder Regisseur zu versuchen. \n",
    "\n",
    "Sie würden z. B. den Mittelwert der Einnahmen eines jeden Genres generieren und die Nullen in jedem Genre mit dem Mittelwert dieses Genres imputieren.\n",
    "\n",
    "Sehen wir uns nun weitere Möglichkeiten an, den Datensatz zu untersuchen und zu verstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 6 (Zusatzaufgabe):**\n",
    "- Generiert den Mittelwert Revenue_Millions pro Genre\n",
    "- Identifiziert die NAN-Values in Revenue_Millions\n",
    "- Ersetzt die Werte mit dem durschschnittlichen Genre\n",
    "\n",
    "**Tipps:**\n",
    "- Schneidet die Genres erst einmal nicht, sondern nutzt jede Kombination\n",
    "- Wenn es für ein Genre kein Mittelwert gibt, nutzt den übergreifenden Mittelwert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Verstehen von Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `.describe()` aufhalten wir eine vollständige Zusammenfassung der Verteilung von **kontinuierlichen Variablen**. Darüber hinaus ist es hilfreich zu wissen welchen Spalten kontinuierlich sind, da die Form der Visualisierung später davon auch mit abhängig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `.describe()` kann auch auf eine kategorische Variable angewendet werden, um die Anzahl der Zeilen, die eindeutige Anzahl der Kategorien, die häufigste Kategorie und die Häufigkeit der obersten Kategorie zu ermitteln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"genre\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.value_counts()` veranschaulicht die Häufigkeit der Werte für eine kategorische Spalte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"genre\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Veranschaulich von Beziehungen zwischen Variablen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Verwendung der Korrelationsmethode `.corr()` können wir die **Korrelation** zwischen den einzelnen kontinuierlichen Variablen erzeugen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korrelationstabellen sind eine numerische Darstellung der bivariaten Beziehungen im Datensatz.\n",
    "\n",
    "Positive Werte bedeuten eine positive Korrelation - der eine Wert steigt, die andere steigt - und negative Zahlen stehen für eine umgekehrte Korrelation - ein Wert steigt, die andere sinkt. 1,0 zeigt eine perfekte Korrelation an. \n",
    "\n",
    "Es gibt anscheinend eine realtiv hohe Korrelation zwischen `votes` and `revenue_millions`. **Frage:** Woran kann das liegen?\n",
    "\n",
    "Die Untersuchung bivariater Beziehungen ist nützlich, wenn Sie ein Ergebnis oder eine abhängige Variable im Auge haben und die Merkmale sehen möchten, die am stärksten mit der Zunahme oder Abnahme des Ergebnisses korrelieren.\n",
    "\n",
    "**Dokumentation:** [`.corr()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DataFrame *slicing, selecting, extracting*\n",
    "\n",
    "Bis jetzt haben wir uns auf einige grundlegende Übersichten und Zusammenfassungen unserer Daten konzentriert. Im Folgenden konzentrieren wir uns auf das Zerlegen, Auswählen und Extrahieren.\n",
    "\n",
    "Es ist zu beachten, dass obwohl viele Methoden gleich sind, DataFrames und Serien unterschiedliche Funktionen haben. Geht also sicher, dass Ihr wisst welche Operation Ihr worauf anwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auswählen einer Spalte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = movies_df[\"genre\"]\n",
    "# Ausgabe des Datentyps\n",
    "type(genre_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies gibt eine *Serie* zurück. Um eine Spalte als **DataFrame** zu extrahieren, müssen wir eine Liste von Spaltennamen übergeben. In unserem Fall ist das nur eine einzelne Spalte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = movies_df[[\"genre\"]]\n",
    "type(genre_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich nur um eine Liste handelt, ist das Hinzufügen eines weiteren Spaltennamens einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = movies_df[[\"genre\", \"rating\"]]\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des weiteren gibt es auch die Möglichkeit **Zeilen** bei *Name* und bei *Index* zu selektieren. Hierfür bietet das Element DataFrame zwei unterschiedliche Funktionen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.loc` - **loc**ates in Bezug auf den Name der Spalte\n",
    "- `.iloc`- **loc**ates in Bezug auf den Numerischen **I**ndex der Zeile\n",
    "\n",
    "Erinnert Euch, dass wir die Tabelle indexiert haben nach dem Titel. Wenn wir `.loc` verwenden, wird es einen Filmtitel benötigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = movies_df.loc[\"Prometheus\"]\n",
    "prom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andererseits können wir über `.iloc` eine bestimmte Zeile auf Basis des numerischen Wertes auswählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = movies_df.iloc[1]\n",
    "\n",
    "prom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` und `iloc` können im weitesten Sinne ähnlich verwendet werden wie das `list slicing` in Python.\n",
    "\n",
    "**Aufgabe 7:**\n",
    "- Selektiere mit `loc` die Titel `Prometheus` bis `Sing`\n",
    "- Selektiere mit `iloc` die Reihen `1 bis 4`\n",
    "- Selektiere mit `iloc` die Reihen 1 und 2, aber als DataFrame und nicht als Serie\n",
    "\n",
    "**Dokumentation:**\n",
    "- [`iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)\n",
    "- [`loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html)\n",
    "- [`isin`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 7.1###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 7.2###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 7.3###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 8 (Zusatzaufgabe):**\n",
    "- Selektiere alle Reihen mit `loc`, die das Genre `Horror` oder `Comedy` haben\n",
    "- Filtere auf `Genre == Comedy` bzw. `Horror` und selektiere die Spalten `director`, `year`, `rating`, `rating_millions` mit Hilfe von `iloc` oder `loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 8.1###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 8.2###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bedingte Selektionen\n",
    "\n",
    "In der letzten Fragestellung der vorangegangenen Aufgabe haben wir ja bereits erste bedingte Selektionen vorgenommen. Das können wir noch etwas weiter führen. Was wäre zum Beispiel, wenn wir unseren `movies_df` so filtern , dass nur Filme von `Ridley Scott` angezeigt werden? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condition = movies_df[\"director\"] == \"Ridley Scott\"\n",
    "condition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich zu `.isnull()`, gibt der Aufruf ene Serie mit `True` und `False` Werten zurück. \n",
    "\n",
    "Nun möchten wir nur die Zeilen selektieren, die tatsächlch Ridley Scott als Direktor des Filmes hatten. Dazu müssen wir die Kondition (==True) in dem DataFrame mit aufnehmen. Übersetzt heißt die Selektion nicht anderes als: \n",
    "> Select movies_df where movies_df director equals Ridley Scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df[\"director\"] == \"Ridley Scott\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 9:** \n",
    "- Wie sehe eine Selektion aus, die nur Filme aufnimmt, dessen **Rating** größer bzw. gleich **8.5** sind?\n",
    "- Welche Filme haben dabei einen Umsatz von mehr als **200 Millionen US-Dollar** gemacht?\n",
    "- Da es anscheinend einige sehr erfolgreiche Direktoren gab, gebe einmal alle Filme aus, die entweder **Christopher Nolan oder Ridley Scott** gemacht haben?\n",
    "- **Zusatzaufgabe:** Was sind die Filme, die **zwischen 2005 und 2010** veröffentlicht wurden, ein **Rating >= 8** haben und dabei in den kleinsten 25% (25th Percentile) sind in Bezug auf die gemachten Umsätze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 9.1###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 9.2###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 9.3###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE 9.4###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ergebnis:** Die letzte Selektion sollte 4 Filme beinhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Anwendung von Funktionen auf das Datenset\n",
    "\n",
    "Es ist möglich bei Iterationen über DataFrame und Serien Funktionen anzuwenden. Dabei sollten performante Funktionen gewählt werden. Über große Datenmengen Schleifen, If-Statements, ect. zu verwenden ist sehr langsam.\n",
    "\n",
    "Hierfür gibt es alternative, effiziente Funktionen - zum Beispiel die Funktion `apply()`. Lasst und diese Funktion einmal in der Dokumentation ansehen und anschließend dafür ein Beispiel definieren.\n",
    "\n",
    "**Dokumentation**: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# pandas.DataFrame.apply\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwds)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `func` erlaubt eine Funktion für den DataFrame zu übergeben\n",
    "- `axis` gibt an, ob die Funktion auf Spalte oder auf Zeilen angewendet werden soll\n",
    "- `raw` erlaubt es die Zeilen nicht als `Series` zu übergeben, sondern als `ndarray objects`\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Beispiel:** Wir würden gerne eine Funktion schreiben, um die Kategorie der Ratings weiter abstrahieren in gute und schlechte Filme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_function(x):\n",
    "    if x >= 8.0:\n",
    "        return \"1\"\n",
    "    else:\n",
    "        return \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wollen wir die gesamte Bewertungsspalte durch diese Funktion schicken, was durch `apply()` geschieht:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df[\"rating_category\"] = movies_df[\"rating\"].apply(rating_function)\n",
    "movies_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Methode `.apply()` übergibt jeden Wert in der Spalte `Rating` durch die `rating_function` und gibt dann eine neue Serie zurück. Diese Serie wird dann einer neuen Spalte namens \"rating_category\" zugewiesen.\n",
    "\n",
    "Ihr könnt auch [anonyme / lambda Funktionen](https://www.programiz.com/python-programming/anonymous-function) verwenden. Diese Lambda-Funktion erzielt das gleiche Ergebnis wie `rating_function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"rating_category\"] = movies_df[\"rating\"].apply(\n",
    "    lambda x: \"good\" if x >= 8.0 else \"bad\"\n",
    ")\n",
    "movies_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wir können auch Funktionen anwenden, die weitere Argumente aufnimmt:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_range(x, lower, higher):\n",
    "    return lower <= x <= higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alle Filme zwischen 2010 und 2020:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df[\"in_range\"] = movies_df[\"year\"].apply(between_range, args=(2015, 2020))\n",
    "movies_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ihr solltet immer versuchen Funktionen wie `.apply()` zu verwenden, weil Pandas hier Elemente von Numpy und Vector-Operationen nutzt.\n",
    "\n",
    "> Vektorisierung: Eine Art der Computerprogrammierung, bei der Operationen auf ganze Arrays statt auf einzelne Elemente angewendet werden — [Array Programming](https://en.wikipedia.org/wiki/Array_programming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Über ein Datenset iterieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt auch einige Möglichkeiten über Datensets zu iterieren, welche aber etwas langsamer sind als Vektoroperationen wie z. B. `.apply()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die erste Methode, um über einen DataFrame zu iterieren, ist die Verwendung von Pandas [`.iterrows()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html), die über den DataFrame mit Hilfe von **Index + Zeile** iteriert.\n",
    "\n",
    "Nach dem Aufruf von **.iterrows()** auf dem DataFrame erhalten wir Zugriff auf den Index, der  Bezeichnung der Zeile und auf die Zeile selbst, die dann als `Series` zur Verfügung gestellt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in movies_df[1:5].iterrows():\n",
    "    print(f'Index: {index}, Genre: {row[\"genre\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Möglichkeit ist `DataFrame.itertuples()`, welches ein Tuple mit Name und die Werte der jeweiligen Zeile wiedergibt. \n",
    "\n",
    "**Dokumentation:** https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in movies_df[1:5].itertuples():\n",
    "    print(f\"(Film, Genre): {row[0]} - {row.genre}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Weitere spalten-orientierte Operationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In gewissen Situationen kann es hilfreich sein, wenn das Datenset nach einer **bestimmten Spalte sortiert** wird. Das kann mit `.sort_values()` erreicht werden.\n",
    "\n",
    "Der erste Parameter der Funktion ist die Spalte des Dataframes, nach der sortiert werden soll. Standardmäßig ist der Parameter `ascending` auf True gesetzt, daher muss dieser nur angeben werden, wenn die Sortierung in absteigender Reihenfolge gewünscht ist.\n",
    "\n",
    "Die Sortierung kan auch mit mehr als einer Spalte vollzugen werden. Hier die **[Dokumentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)**. Es gibt noch einige weitere Operationen, die die Sortierung spezifizieren `na_position` oder `kind`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df.sort_values(by=[\"year\", \"revenue_millions\"], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Du möchtest, kannst Du im Dataset auch bestimmte Spalten **[droppen](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)**, wenn diese für die weitere Analyse nicht mehr benötigt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.drop(\"in_range\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es kann auch interessant sein, den Durchschnitt der Ratings und die Summe der Umsätze von Filmen über die jeweiligen Jahre auszugeben. Hierfür müssen wir erst einmal auf das jeweilige Jahr aggregieren und anschließend die Funktion `agg` verwenden, um die **Summe** und den **Durchschnitt** zu berechnen. Hier die [Dokumentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[[\"year\", \"revenue_millions\"]].groupby([\"year\"]).agg([\"sum\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist nur eine **Einführung in Pandas** - hier auch noch einmal weitere Materialien für das weitere Selbststudium. Die Ressourcen sind aber hier endlos, da dieses Package so weit verbreitet ist:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Community Tutorials auf Basis der offiziellen Pandas Dokumentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)\n",
    "- [Community Tutorials, Notebooks und Analysen von Kaggle](https://www.kaggle.com/code?searchQuery=Pandas)\n",
    "- [3 Methods to Create Conditional Columns with Python Pandas and Numpy](https://towardsdatascience.com/all-probability-distributions-explained-in-six-minutes-fe57b1d49600)\n",
    "- [Filtering Data in Pandas](https://levelup.gitconnected.com/filtering-data-in-pandas-c7b60d1e1301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 10 (Zusatzaufgabe)**: Separiere die Komma-separierte Genre-Spalte und kreiere eine Spalte pro Genre, für welche die jweilige Zeile bei angegebenen Genres den Wert 1 ausgibt. Für nicht enthaltene Genres gibt es den Wert 0 aus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
